

### Lab 2 Code Explanation as a Simple Model Context Protocol (MCP)

This Arduino code uses a Finite State Machine (FSM) to define and manage the high-level operational flow for an embedded system focused on image processing and data telemetry. It acts as the "Master Control" for this specific sequence of events.

| Step in Model Context Protocol (MCP) | Description in Code's Context | FSM's Role in this Code |
| :----------------------------------- | :----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **1. Sense Environment / Input Reception** | The system obtains raw data, primarily through the camera, and also tracks time as an implicit input for process timing. | The **FSM's current state determines *what* is sensed.** When the FSM is in the `CAPTURE` state, it actively uses the camera hardware (`esp_camera_fb_get()`) to "sense" the environment (take a picture). The `loop()` continuously monitors `millis()` (a time input) to check if the `duration` for the current state has elapsed, triggering the next phase. |
| **2. Context Recognition / State Identification** | The system explicitly knows its current operational mode or what phase of the image processing pipeline it's in. There are four predefined contexts: `CAPTURE` (camera active), `CLASSIFY` (processing image), `TRANSMIT` (sending data), or `WAIT` (idle). | The **FSM's defined `states` (`CAPTURE`, `CLASSIFY`, `TRANSMIT`, `WAIT`) *are* the system's explicit contexts or operational modes.** The `currentStateIndex` always points to the active context. The `onEnter` and `onExit` hooks visually indicate context changes as they occur. |
| **3. Model Selection / Task Activation** | Based on the recognized context, the system calls the specific task or algorithm designed for that phase. | The **FSM directly maps each `StateConfig` entry to a specific `handler` function** (`captureState`, `classifyState`, `transmitState`, `waitState`). When the FSM enters a state, its associated handler function is invoked. This implicitly selects the relevant "model" (camera operation, classification simulation, data formatting/send) for execution in that context. |
| **4. Model Execution / Interaction** | The selected task or "model" performs its designated operation, e.g., interfacing with the camera, generating (simulated) classification results, or preparing data for output. | Within the `loop()`, `current.handler()` directly executes the code associated with the current FSM state. The FSM also implicitly controls the *duration* of this execution via the `duration` parameter in `StateConfig`, ensuring the model/task runs for a predetermined period within its context. |
| **5. Output Interpretation / Action Generation** | The results from the executed task are processed. For example, a captured image is ready, or a classification label and confidence are determined, or a JSON string is ready for upload. | The outputs of the `handler` functions (like `label`, `confidence`, the formatted `result` string) are generated within each state. While this current code doesn't use these outputs for *conditional FSM transitions*, the FSM implicitly ensures they are available for the *next* sequential state (e.g., `label` and `confidence` from `classifyState` are accessible by `transmitState`). |
| **6. Context Update / State Transition** | Based on the completion of the current task's allocated time, the system transitions to the next defined operational context. | This is the **core, explicit function of the FSM in the `loop()` function.** After the `current.handler()` is called, the code checks if the state's `duration` has passed. If so, it uses the hardcoded `current.next` field to find and set the `currentStateIndex` to the subsequent state. The `onExit` and `onEnter` hooks mark these transitions. |
| **7. Loop / Goal Progression** | The system repeatedly cycles through these steps, autonomously performing its intended function of image capture, classification, and data transmission. | The **FSM inherently defines the system's continuous, cyclical operation.** By always being in one state and having a pre-defined `next` state, the FSM guarantees a clear, sequential progression through the entire process (Capture -> Classify -> Transmit -> Wait -> Capture...). This establishes a predictable and continuous autonomous process. |

---

This code provides a crystal-clear example of an FSM acting as an MCP: it sets up the distinct operational contexts, selects the appropriate "tools" (code functions) for each, executes them, and then predictably moves to the next context in the sequence.
